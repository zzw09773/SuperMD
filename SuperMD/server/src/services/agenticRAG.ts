import { ChatOpenAI } from '@langchain/openai';
import { StateGraph, Annotation, END } from '@langchain/langgraph';
import { BaseMessage, HumanMessage, AIMessage, SystemMessage } from '@langchain/core/messages';
import { DynamicTool } from '@langchain/core/tools';
import { searchSimilarDocuments, getUserDocuments } from './ragService';
import {
  appendAgentMemory,
  collectConversationContext,
  loadAgentMemory,
  memoryToMessages,
  type AgentMemoryEntryInput,
} from '../lib/agentMemory';
import { requireLLMConfig } from '../config/aiConfig';
import dotenv from 'dotenv';

dotenv.config();

const RAG_MEMORY_MODE = 'rag';

async function buildRAGMemory(userId: string) {
  const memory = await loadAgentMemory(userId, RAG_MEMORY_MODE);
  return {
    memory,
    context: collectConversationContext(memory),
    messages: memoryToMessages(memory, 'RAG å°è©±æ‘˜è¦'),
  };
}

// ============================================================
// 1ï¸âƒ£ STATE: å®šç¾© Agent ç‹€æ…‹
// ============================================================

/**
 * AgentState å®šç¾© Agentic RAG çš„ç‹€æ…‹çµæ§‹
 * - messages: å°è©±æ­·å²ï¼ˆç´¯åŠ ï¼‰
 * - query: åŸå§‹ç”¨æˆ¶æŸ¥è©¢
 * - rewrittenQuery: æ”¹å¯«å¾Œçš„æŸ¥è©¢ï¼ˆå¯é¸ï¼‰
 * - ragResults: æª¢ç´¢çµæœ
 * - shouldRetrieve: æ˜¯å¦éœ€è¦æª¢ç´¢
 * - answer: æœ€çµ‚ç­”æ¡ˆ
 * - steps: æ¨ç†æ­¥é©Ÿï¼ˆç”¨æ–¼ SSE ä¸²æµï¼‰
 */
const AgentState = Annotation.Root({
  messages: Annotation<BaseMessage[]>({
    reducer: (current, update) => current.concat(update),
    default: () => [],
  }),
  query: Annotation<string>({
    reducer: (_, update) => update,
    default: () => '',
  }),
  rewrittenQuery: Annotation<string | null>({
    reducer: (_, update) => update,
    default: () => null,
  }),
  ragResults: Annotation<string>({
    reducer: (_, update) => update,
    default: () => '',
  }),
  shouldRetrieve: Annotation<boolean>({
    reducer: (_, update) => update,
    default: () => true,
  }),
  shouldListDocuments: Annotation<boolean>({
    reducer: (_, update) => update,
    default: () => false,
  }),
  answer: Annotation<string>({
    reducer: (_, update) => update,
    default: () => '',
  }),
  steps: Annotation<Array<{ type: string; content: string }>>({
    reducer: (current, update) => current.concat(update),
    default: () => [],
  }),
  userId: Annotation<string>({
    reducer: (_, update) => update,
    default: () => '',
  }),
});

type AgentStateType = typeof AgentState.State;

// ============================================================
// 2ï¸âƒ£ TOOLS: å®šç¾© Agent å¯ç”¨çš„å·¥å…·
// ============================================================

/**
 * Tool 1: Query Rewriter
 * å°‡ç”¨æˆ¶æŸ¥è©¢æ”¹å¯«ç‚ºæ›´é©åˆå‘é‡æª¢ç´¢çš„å½¢å¼
 */
const createQueryRewriterTool = (
  llm: ChatOpenAI,
  getContext: () => Promise<{ lastQuery?: string; lastAnswer?: string; lastSources?: string[] }>
) => {
  return new DynamicTool({
    name: 'query_rewriter',
    description: `Rewrites user queries to be more suitable for vector similarity search.
    Use this when the original query is too vague, conversational, or needs clarification.
    Input: original query string
    Output: rewritten query optimized for retrieval`,
    func: async (query: string) => {
      try {
        console.log(`?? [Query Rewriter] Original: "${query}"`);

        const context = await getContext();
        const contextLines: string[] = [];

        if (context.lastQuery) {
          contextLines.push(`Previous question: ${context.lastQuery}`);
        }

        if (context.lastAnswer) {
          contextLines.push(`Previous answer: ${context.lastAnswer}`);
        }

        if (context.lastSources && context.lastSources.length > 0) {
          contextLines.push(`Referenced documents: ${context.lastSources.join(', ')}`);
        }

        const contextBlock = contextLines.length > 0
          ? `Conversation context cannot be ignored. Latest information:
${contextLines.join('\n')}

`
          : '';

        const prompt = `${contextBlock}You are a query optimization expert. Extract the core keywords from the user's query for better semantic search.

Original Query: "${query}"

Rules:
1. Extract ONLY the main keywords and concepts (3-5 keywords maximum)
2. Remove conversational words (e.g., "è«‹å¹«æˆ‘", "å¦‚ä½•", "can you", "how to")
3. Keep technical terms and specific nouns
4. Use the same language as the original query
5. Separate keywords with spaces, NO explanations or descriptions

Example:
Input: "å¹³é¢å‘é‡å¦‚ä½•è¡¨ç¤º"
Output: "å¹³é¢å‘é‡ è¡¨ç¤ºæ³•"

Input: "è«‹å‘Šè¨´æˆ‘å°æ•¸å‡½æ•¸çš„å®šç¾©"
Output: "å°æ•¸å‡½æ•¸ å®šç¾©"

Keywords:`;

        const response = await llm.invoke([new HumanMessage(prompt)]);
        const rewrittenQuery = response.content.toString().trim();

        console.log(`? [Query Rewriter] Rewritten: "${rewrittenQuery}"`);
        return rewrittenQuery;
      } catch (error) {
        console.error('[Query Rewriter] Error:', error);
        return query; // Fallback to original
      }
    },
  });
};

/**
 * Tool 2: Knowledge Base Search
 * å¾ç”¨æˆ¶çš„çŸ¥è­˜åº«ä¸­æª¢ç´¢ç›¸é—œæ–‡ä»¶
 */
const createKnowledgeBaseSearchTool = (userId: string) => {
  return new DynamicTool({
    name: 'knowledge_base_search',
    description: `Searches the user's knowledge base (uploaded documents) for relevant information.
    Input: search query string (use rewritten query if available)
    Output: relevant text chunks with similarity scores and source files`,
    func: async (query: string) => {
      try {
        console.log(`ğŸ” [KB Search] Searching: "${query}"`);

        const results = await searchSimilarDocuments(query, userId, 5);

        if (results.length === 0) {
          return 'No relevant information found in the knowledge base. The user may need to upload relevant documents first.';
        }

        // Format results with source attribution
        const formattedResults = results
          .map((result, idx) => {
            return `[Source ${idx + 1}: ${result.fileName} | Similarity: ${(result.similarity * 100).toFixed(1)}%]
${result.content}
---`;
          })
          .join('\n');

        console.log(`âœ… [KB Search] Found ${results.length} relevant chunks`);
        return formattedResults;
      } catch (error) {
        console.error('[KB Search] Error:', error);
        return 'Error searching knowledge base: ' + (error instanceof Error ? error.message : 'Unknown error');
      }
    },
  });
};

/**
 * Tool 3: Document List
 * åˆ—å‡ºç”¨æˆ¶çŸ¥è­˜åº«ä¸­çš„æ‰€æœ‰æ–‡ä»¶
 */
const createDocumentListTool = (userId: string) => {
  return new DynamicTool({
    name: 'list_documents',
    description: `Lists all documents currently in the user's knowledge base.
    Use this when the user asks what documents/files/knowledge they have uploaded,
    or asks about the contents/overview of their knowledge base.
    Input: empty string (no input needed)
    Output: formatted list of all documents with metadata`,
    func: async () => {
      try {
        console.log(`ğŸ“‹ [Document List] Fetching all documents for user: ${userId}`);

        const documents = await getUserDocuments(userId);

        if (documents.length === 0) {
          return 'The knowledge base is currently empty. No documents have been uploaded yet.';
        }

        // Format the document list
        const formattedList = documents
          .map((doc, idx) => {
            const sizeMB = (doc.fileSize / (1024 * 1024)).toFixed(2);
            const date = new Date(doc.createdAt).toLocaleDateString('zh-TW');
            return `${idx + 1}. **${doc.fileName}**
   - æª”æ¡ˆé¡å‹: ${doc.fileType}
   - å¤§å°: ${sizeMB} MB
   - åˆ†å¡Šæ•¸: ${doc.chunkCount} å€‹
   - ä¸Šå‚³æ™‚é–“: ${date}`;
          })
          .join('\n\n');

        console.log(`âœ… [Document List] Found ${documents.length} documents`);
        return `çŸ¥è­˜åº«åŒ…å«ä»¥ä¸‹ ${documents.length} å€‹æ–‡ä»¶:\n\n${formattedList}`;
      } catch (error) {
        console.error('[Document List] Error:', error);
        return 'Error retrieving document list: ' + (error instanceof Error ? error.message : 'Unknown error');
      }
    },
  });
};

/**
 * Tool 4: Relevance Evaluator
 * è©•ä¼°æª¢ç´¢çµæœæ˜¯å¦è¶³å¤ å›ç­”å•é¡Œ
 */
const createRelevanceEvaluatorTool = (llm: ChatOpenAI) => {
  return new DynamicTool({
    name: 'relevance_evaluator',
    description: `Evaluates if the retrieved documents contain sufficient information to answer the user's question.
    Input: JSON string with {query, results}
    Output: "SUFFICIENT" or "INSUFFICIENT" with reasoning`,
    func: async (input: string) => {
      try {
        const { query, results } = JSON.parse(input);
        console.log(`ğŸ“Š [Relevance Eval] Evaluating results for: "${query}"`);

        const prompt = `You are a relevance evaluator. Determine if the retrieved documents contain sufficient information to answer the user's question.

User Question: "${query}"

Retrieved Documents:
${results}

Evaluate:
1. Do the documents contain relevant information?
2. Is the information sufficient to provide a complete answer?
3. Are there any gaps in the information?

Respond with ONLY one word: "SUFFICIENT" or "INSUFFICIENT"
Then provide a brief 1-sentence explanation.

Format:
SUFFICIENT: [reason] OR INSUFFICIENT: [reason]`;

        const response = await llm.invoke([new HumanMessage(prompt)]);
        const evaluation = response.content.toString().trim();

        console.log(`ğŸ“Š [Relevance Eval] Result: ${evaluation}`);
        return evaluation;
      } catch (error) {
        console.error('[Relevance Eval] Error:', error);
        return 'SUFFICIENT: Proceeding with available information';
      }
    },
  });
};

// ============================================================
// 3ï¸âƒ£ NODES: å®šç¾© Graph çš„ç¯€é»ï¼ˆè™•ç†é‚è¼¯ï¼‰
// ============================================================

/**
 * Node 1: Router - æ±ºå®šæ˜¯å¦éœ€è¦æ”¹å¯«æŸ¥è©¢æˆ–åˆ—å‡ºæ–‡ä»¶
 */
const routerNode = async (state: AgentStateType): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ”€ [Router Node] Analyzing query...');

  const { query } = state;

  // æª¢æ¸¬æ˜¯å¦æ˜¯ã€Œåˆ—å‡ºæ–‡ä»¶/çŸ¥è­˜é»ã€é¡çš„æŸ¥è©¢
  const isListQuery =
    query.includes('æœ‰å“ªäº›') ||
    query.includes('åŒ…å«å“ªäº›') ||
    query.includes('åˆ—å‡º') ||
    query.includes('æ‰€æœ‰æ–‡ä»¶') ||
    query.includes('æ‰€æœ‰çŸ¥è­˜') ||
    query.includes('çŸ¥è­˜åº«å…§å®¹') ||
    query.toLowerCase().includes('what documents') ||
    query.toLowerCase().includes('list all');

  if (isListQuery) {
    const step = {
      type: 'reasoning',
      content: 'ğŸ“‹ æª¢æ¸¬åˆ°æ–‡ä»¶åˆ—è¡¨æŸ¥è©¢ï¼Œå°‡åˆ—å‡ºçŸ¥è­˜åº«æ‰€æœ‰æ–‡ä»¶',
    };
    return {
      shouldListDocuments: true,
      shouldRetrieve: false,
      steps: [step],
    };
  }

  // å…ˆç›´æ¥æª¢ç´¢ï¼Œä¸é å…ˆåˆ¤æ–·æ˜¯å¦éœ€è¦æ”¹å¯«
  const step = {
    type: 'reasoning',
    content: 'ğŸ” é–‹å§‹æœå°‹çŸ¥è­˜åº«...',
  };

  return {
    shouldRetrieve: false, // å…ˆä¸æ”¹å¯«ï¼Œç›´æ¥æª¢ç´¢
    shouldListDocuments: false,
    steps: [step],
  };
};

/**
 * Node 2: Query Rewriter - æ”¹å¯«æŸ¥è©¢
 */
const queryRewriterNode = async (
  state: AgentStateType,
  tools: { queryRewriter: DynamicTool }
): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ“ [Query Rewriter Node] Rewriting query...');

  const { query } = state;
  const rewrittenQuery = await tools.queryRewriter.func(query);

  const step = {
    type: 'tool_call',
    content: `ğŸ”„ æŸ¥è©¢æ”¹å¯«: "${query}" â†’ "${rewrittenQuery}"`,
  };

  return {
    rewrittenQuery,
    steps: [step],
  };
};

/**
 * Node 3: Retriever - åŸ·è¡ŒçŸ¥è­˜åº«æª¢ç´¢
 */
const retrieverNode = async (
  state: AgentStateType,
  tools: { kbSearch: DynamicTool }
): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ” [Retriever Node] Searching knowledge base...');

  const { query, rewrittenQuery } = state;
  const searchQuery = rewrittenQuery || query;

  const results = await tools.kbSearch.func(searchQuery);

  const step = {
    type: 'tool_call',
    content: `ğŸ” çŸ¥è­˜åº«æª¢ç´¢: ä½¿ç”¨æŸ¥è©¢ "${searchQuery}"`,
  };

  return {
    ragResults: results,
    steps: [step],
  };
};

/**
 * Node 4: Evaluator - è©•ä¼°æª¢ç´¢çµæœ
 */
const evaluatorNode = async (
  state: AgentStateType,
  tools: { relevanceEval: DynamicTool }
): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ“Š [Evaluator Node] Evaluating relevance...');

  const { query, ragResults } = state;

  const evaluation = await tools.relevanceEval.func(
    JSON.stringify({ query, results: ragResults })
  );

  const isSufficient = evaluation.toUpperCase().includes('SUFFICIENT');

  const step = {
    type: 'reasoning',
    content: `ğŸ“Š çµæœè©•ä¼°: ${evaluation}`,
  };

  return {
    shouldRetrieve: !isSufficient,
    steps: [step],
  };
};

/**
 * Node 5: Document Lister - åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
 */
const documentListerNode = async (
  state: AgentStateType,
  tools: { documentList: DynamicTool }
): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ“‹ [Document Lister Node] Listing all documents...');

  const documentList = await tools.documentList.func('');

  const step = {
    type: 'tool_call',
    content: 'ğŸ“‹ å·²åˆ—å‡ºçŸ¥è­˜åº«æ‰€æœ‰æ–‡ä»¶',
  };

  return {
    ragResults: documentList,
    answer: documentList,
    steps: [step],
    messages: [new AIMessage(documentList)],
  };
};

/**
 * Node 6: Generator - ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
 */
const generatorNode = async (
  state: AgentStateType,
  llm: ChatOpenAI
): Promise<Partial<AgentStateType>> => {
  console.log('\nğŸ’¬ [Generator Node] Generating answer...');

  const { query, ragResults } = state;

  const prompt = `IMPORTANT: You MUST respond in Traditional Chinese (ç¹é«”ä¸­æ–‡, zh-TW) ONLY.

You are a helpful AI assistant. Use the following information from the user's knowledge base to answer their question in Traditional Chinese.

Knowledge Base Results:
${ragResults}

User Question: ${query}

Instructions:
1. Answer in Traditional Chinese (ç¹é«”ä¸­æ–‡) ONLY
2. Answer the question based ONLY on the information provided above
3. If the information is not sufficient, say so clearly in Traditional Chinese
4. Always cite which source you used (e.g., "æ ¹æ“š Source 1...")
5. Be concise and accurate
6. Format your answer in Markdown for better readability

Answer (in Traditional Chinese ç¹é«”ä¸­æ–‡):`;

  const response = await llm.invoke([new HumanMessage(prompt)]);
  const answer = response.content.toString();

  const step = {
    type: 'chunk',
    content: 'ğŸ’¬ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...',
  };

  return {
    answer,
    steps: [step],
    messages: [new AIMessage(answer)],
  };
};

// ============================================================
// 4ï¸âƒ£ AGENT: çµ„è£ StateGraph å‰µå»º Agentic RAG
// ============================================================

/**
 * å‰µå»ºå®Œæ•´çš„ Agentic RAG Agent
 */
export const createAgenticRAG = (
  userId: string,
  contextLoader: () => Promise<{ lastQuery?: string; lastAnswer?: string; lastSources?: string[] }>
) => {
  // Initialize LLM
  const llmConfig = requireLLMConfig('AgenticRAG');
  const llm = new ChatOpenAI({
    modelName: llmConfig.modelName,
    temperature: 1, // GPT-5 only supports temperature=1
    configuration: {
      apiKey: llmConfig.apiKey,
      baseURL: llmConfig.baseURL,
    },
  });

  // Create tools
  const tools = {
    queryRewriter: createQueryRewriterTool(llm, contextLoader),
    kbSearch: createKnowledgeBaseSearchTool(userId),
    documentList: createDocumentListTool(userId),
    relevanceEval: createRelevanceEvaluatorTool(llm),
  };

  // Build the graph
  const workflow = new StateGraph(AgentState)
    // Add nodes
    .addNode('router', routerNode)
    .addNode('rewriter', (state: AgentStateType) => queryRewriterNode(state, tools))
    .addNode('retriever', (state: AgentStateType) => retrieverNode(state, tools))
    .addNode('evaluator', (state: AgentStateType) => evaluatorNode(state, tools))
    .addNode('documentLister', (state: AgentStateType) => documentListerNode(state, tools))
    .addNode('generator', (state: AgentStateType) => generatorNode(state, llm))

    // Define edges (workflow logic)
    .addEdge('__start__', 'router')
    .addConditionalEdges(
      'router',
      (state: AgentStateType) => {
        // å¦‚æœæ˜¯åˆ—å‡ºæ–‡ä»¶æŸ¥è©¢ï¼Œç›´æ¥åˆ—å‡º
        if (state.shouldListDocuments) {
          return 'documentLister';
        }
        // å…¶ä»–æ‰€æœ‰æŸ¥è©¢éƒ½å…ˆç›´æ¥æª¢ç´¢
        return 'retriever';
      },
      {
        documentLister: 'documentLister',
        retriever: 'retriever',
      }
    )
    .addEdge('documentLister', END)
    .addEdge('rewriter', 'retriever')
    .addEdge('retriever', 'evaluator')
    .addConditionalEdges(
      'evaluator',
      (state: AgentStateType) => {
        // å¦‚æœå·²ç¶“æ”¹å¯«éäº†ï¼Œä¸å†é‡è©¦ï¼Œç›´æ¥ç”Ÿæˆç­”æ¡ˆ
        if (state.rewrittenQuery) {
          return 'generator';
        }
        // å¦‚æœçµæœä¸è¶³ä¸”é‚„æ²’æ”¹å¯«éï¼Œå˜—è©¦æ”¹å¯«æŸ¥è©¢
        if (state.shouldRetrieve) {
          return 'rewriter';
        }
        // çµæœå……è¶³ï¼Œç”Ÿæˆç­”æ¡ˆ
        return 'generator';
      },
      {
        rewriter: 'rewriter',
        generator: 'generator',
      }
    )
    .addEdge('generator', END);

  return workflow.compile();
};

/**
 * Query the Agentic RAG system
 */
export const queryAgenticRAG = async (
  userId: string,
  query: string
): Promise<{
  answer: string;
  sources: string[];
  steps: Array<{ type: string; content: string }>;
}> => {
  try {
    console.log(`\nğŸ¤– [Agentic RAG] Processing query: "${query}"`);
    console.log(`ğŸ‘¤ User ID: ${userId}`);

    const { messages: previousMessages, context } = await buildRAGMemory(userId);

    const agent = createAgenticRAG(userId, async () => context);

    const initialState = {
      query,
      userId,
      messages: [...previousMessages, new HumanMessage(query)],
      steps: [],
    };

    const finalState = await agent.invoke(initialState);

    // Extract sources from RAG results
    const sources: string[] = [];
    const sourceMatches = finalState.ragResults.match(/\[Source \d+: ([^\]]+?)\s*\|/g);
    if (sourceMatches) {
      sourceMatches.forEach((match: string) => {
        const fileName = match.match(/\[Source \d+: ([^\]]+?)\s*\|/)?.[1];
        if (fileName && !sources.includes(fileName)) {
          sources.push(fileName);
        }
      });
    }

    console.log(`âœ… [Agentic RAG] Query completed`);
    console.log(`ğŸ“ Steps taken: ${finalState.steps.length}`);
    console.log(`ğŸ“š Sources used: ${sources.length}`);
    const memoryEntries: AgentMemoryEntryInput[] = [
      { role: 'human' as const, content: query },
      {
        role: 'assistant' as const,
        content: finalState.answer,
        metadata: sources.length ? { sources } : undefined,
      },
    ];

    if (sources.length > 0) {
      memoryEntries.push({
        role: 'system' as const,
        content: `SOURCES: ${sources.join(', ')}`,
        metadata: { type: 'sources', sources },
      });
    }

    await appendAgentMemory(userId, RAG_MEMORY_MODE, memoryEntries);

    return {
      answer: finalState.answer,
      sources,
      steps: finalState.steps,
    };
  } catch (error) {
    console.error('âŒ [Agentic RAG] Query error:', error);
    throw error;
  }
};

/**
 * Streaming version for SSE support
 */
export async function* streamAgenticRAG(
  userId: string,
  query: string
): AsyncGenerator<{ type: string; content: string; done?: boolean; answer?: string; sources?: string[] }> {
  try {
    console.log(`\nğŸ¬ [Agentic RAG Stream] Starting: "${query}"`);

    const { messages: previousMessages, context } = await buildRAGMemory(userId);

    const agent = createAgenticRAG(userId, async () => context);

    const initialState = {
      query,
      userId,
      messages: [...previousMessages, new HumanMessage(query)],
      steps: [],
    };

    // Stream each step
    for await (const event of await agent.stream(initialState)) {
      const nodeName = Object.keys(event)[0];
      const nodeState = (event as Record<string, AgentStateType>)[nodeName];

      console.log(`ğŸ“¡ [Stream] Node: ${nodeName}`);

      // Stream steps as they happen
      if (nodeState.steps && nodeState.steps.length > 0) {
        for (const step of nodeState.steps) {
          yield {
            type: step.type,
            content: step.content,
          };
        }
      }
    }

    // Get final state
    const finalState = await agent.invoke(initialState);

    // Extract sources
    const sources: string[] = [];
    const sourceMatches = finalState.ragResults.match(/\[Source \d+: ([^\]]+?)\s*\|/g);
    if (sourceMatches) {
      sourceMatches.forEach((match: string) => {
        const fileName = match.match(/\[Source \d+: ([^\]]+?)\s*\|/)?.[1];
        if (fileName && !sources.includes(fileName)) {
          sources.push(fileName);
        }
      });
    }

    // Final result
    yield {
      type: 'done',
      content: finalState.answer,
      done: true,
      answer: finalState.answer,
      sources,
    };
    const memoryEntries: AgentMemoryEntryInput[] = [
      { role: 'human' as const, content: query },
      {
        role: 'assistant' as const,
        content: finalState.answer,
        metadata: sources.length ? { sources } : undefined,
      },
    ];

    if (sources.length > 0) {
      memoryEntries.push({
        role: 'system' as const,
        content: `SOURCES: ${sources.join(', ')}`,
        metadata: { type: 'sources', sources },
      });
    }

    await appendAgentMemory(userId, RAG_MEMORY_MODE, memoryEntries);

    console.log(`âœ… [Agentic RAG Stream] Completed`);
  } catch (error) {
    console.error('âŒ [Agentic RAG Stream] Error:', error);
    yield {
      type: 'error',
      content: error instanceof Error ? error.message : 'Unknown error',
      done: true,
    };
  }
}

